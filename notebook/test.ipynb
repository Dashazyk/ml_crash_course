{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp38-none-win_amd64.whl (74.0 MB)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (5.3.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.22.3)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (0.16)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.1.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from catboost) (1.5.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting text_preprocessing\n",
      "  Downloading text_preprocessing-0.1.1-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting names-dataset==2.1\n",
      "  Downloading names_dataset-2.1.0-py3-none-any.whl (62.6 MB)\n",
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting unittest-xml-reporting\n",
      "  Downloading unittest_xml_reporting-3.2.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.7.1-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from text_preprocessing) (3.5)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from unittest-xml-reporting->text_preprocessing) (4.6.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->text_preprocessing) (0.17.0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->text_preprocessing) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->text_preprocessing) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->text_preprocessing) (2020.10.15)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.4-cp38-cp38-win_amd64.whl (39 kB)\n",
      "Installing collected packages: names-dataset, anyascii, pyahocorasick, textsearch, contractions, unittest-xml-reporting, pyspellchecker, text-preprocessing\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.73 names-dataset-2.1.0 pyahocorasick-1.4.4 pyspellchecker-0.7.1 text-preprocessing-0.1.1 textsearch-0.0.24 unittest-xml-reporting-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install text_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "from text_preprocessing import to_lower, remove_number, remove_whitespace, preprocess_text, remove_stopword, remove_punctuation, remove_special_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num rows for train: %d 5233\n"
     ]
    }
   ],
   "source": [
    "input_file = '/home/dasha/Documents/ml_crash_course/data/labeled_data_corpus.csv'\n",
    "if not os.path.exists(input_file):\n",
    "    raise RuntimeError(f'No input file: {input_file}')\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "train_df = df[df['subset'] == 'train']\n",
    "test_df = df[df['subset'] == 'test']\n",
    "print('num rows for train: %d', train_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['msg']\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_test = test_df['msg']\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    здравствуйте. ишу 2х спальную квартиру в лимас...\n",
       "1    #сниму  комнату в лимассоле или недалеко от не...\n",
       "2                        мошенник риэлторским услугам.\n",
       "3    **sales**    reg.1053 lic.489/e **stylish apar...\n",
       "4    важно: [valerii korol](tg://user?id=193474890)...\n",
       "5    аренда  no: 367/e ️ларнака️между пила и декели...\n",
       "6    привет  ищу виллу посуточно с бюджетом 2000€ в...\n",
       "7    важно: [liss](tg://user?id=202814885), если ты...\n",
       "8                               total messages: 126772\n",
       "9    аренда  ️ларнака ️в центре города️ saint lazar...\n",
       "Name: msg, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    здравствуйте ишу х спальную квартиру лимассоле...\n",
      "1    сниму комнату лимассоле недалеко начала август...\n",
      "2                         мошенник риэлторским услугам\n",
      "3    sales reg lice stylish apartment with sea view...\n",
      "4    важно valerii koroltguserid бот спамер пройди ...\n",
      "5    аренда no e ️ларнака️между пила декелия ️ пеше...\n",
      "6    привет ищу виллу посуточно бюджетом € сутки дн...\n",
      "7    важно lisstguserid бот спамер пройди проверку ...\n",
      "8                                       total messages\n",
      "9    аренда ️ларнака ️в центре города️ saint lazaro...\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "X_train = X_train.str.lower()\n",
    "X_train = X_train.dropna()\n",
    "\n",
    "preprocess_functions = [to_lower, remove_punctuation, remove_special_character, remove_number, remove_whitespace]\n",
    "X_train = X_train.apply(lambda x: preprocess_text(x, preprocess_functions))\n",
    "\n",
    "X_train = X_train.map(lambda x: bytes(x, 'utf-8').decode('utf-8', 'ignore'))\n",
    "\n",
    "#english_stopwords = stopwords.words(\"english\")\n",
    "#X_train = X_train.apply(lambda x: remove_stopword(x, english_stopwords))\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "X_train = X_train.apply(lambda x: remove_stopword(x, russian_stopwords))\n",
    "\n",
    "greek_stopwords = stopwords.words(\"greek\")\n",
    "X_train = X_train.apply(lambda x: remove_stopword(x, greek_stopwords))\n",
    "\n",
    "turkish_stopwords = stopwords.words(\"turkish\")\n",
    "X_train = X_train.apply(lambda x: remove_stopword(x, turkish_stopwords))\n",
    "\n",
    "X_train = X_train.str.join(' ')\n",
    "\n",
    "print(X_train[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15580"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = list(X_train.str.split(' ', expand=True).stack().unique())\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train.apply(lambda x: len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.82094400917256"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum() / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5233    сдам собственник лимассол сдаю комнатную новую...\n",
      "5234    важно tianatguserid бот спамер пройди проверку...\n",
      "5235    привет аленаtguserid это бесплатная группа аре...\n",
      "5236    привет meds mtguserid это бесплатная группа ар...\n",
      "5237    аренда район линопетра лимассол долгосрочную а...\n",
      "5238                                     клиент приезжает\n",
      "5239                       james michaeltguserid забанили\n",
      "5240    сдается квартира пафосе район хлорака м спальн...\n",
      "5241    аренда х комнатного дома джакузи выходом крышу...\n",
      "5242    квартира спальнями ванной комнатой верандами к...\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "X_test = X_test.str.lower()\n",
    "X_test = X_test.dropna()\n",
    "\n",
    "preprocess_functions = [to_lower, remove_punctuation, remove_special_character, remove_number, remove_whitespace]\n",
    "X_test = X_test.apply(lambda x: preprocess_text(x, preprocess_functions))\n",
    "\n",
    "X_test = X_test.map(lambda x: bytes(x, 'utf-8').decode('utf-8', 'ignore'))\n",
    "\n",
    "#english_stopwords = stopwords.words(\"english\")\n",
    "#X_test = X_test.apply(lambda x: remove_stopword(x, english_stopwords))\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "X_test = X_test.apply(lambda x: remove_stopword(x, russian_stopwords))\n",
    "\n",
    "greek_stopwords = stopwords.words(\"greek\")\n",
    "X_test = X_test.apply(lambda x: remove_stopword(x, greek_stopwords))\n",
    "\n",
    "turkish_stopwords = stopwords.words(\"turkish\")\n",
    "X_test = X_test.apply(lambda x: remove_stopword(x, turkish_stopwords))\n",
    "\n",
    "X_test = X_test.str.join(' ')\n",
    "\n",
    "print(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5233"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'здравствуйте ишу х спальную квартиру лимассоле желательно гермасойя семья х взрослых х детей животных длительный срок бюджет евро предложения лс'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.3, min_df=0.01).fit(X_train)\n",
    "X_train_csr = vectorizer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csr = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5233x543 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 100992 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7493380\ttest: 0.7115717\tbest: 0.7115717 (0)\ttotal: 60.3ms\tremaining: 5m 1s\n",
      "500:\tlearn: 0.8794821\ttest: 0.8310139\tbest: 0.8326693 (454)\ttotal: 24.7s\tremaining: 3m 42s\n",
      "1000:\tlearn: 0.9160156\ttest: 0.8410853\tbest: 0.8410853 (967)\ttotal: 47.9s\tremaining: 3m 11s\n",
      "1500:\tlearn: 0.9323017\ttest: 0.8544061\tbest: 0.8560461 (1482)\ttotal: 1m 10s\tremaining: 2m 44s\n",
      "2000:\tlearn: 0.9427058\ttest: 0.8587786\tbest: 0.8625954 (1930)\ttotal: 1m 33s\tremaining: 2m 20s\n",
      "2500:\tlearn: 0.9508197\ttest: 0.8657845\tbest: 0.8657845 (2460)\ttotal: 1m 57s\tremaining: 1m 57s\n",
      "3000:\tlearn: 0.9576516\ttest: 0.8754717\tbest: 0.8754717 (2982)\ttotal: 2m 19s\tremaining: 1m 33s\n",
      "3500:\tlearn: 0.9620010\ttest: 0.8754717\tbest: 0.8771267 (3040)\ttotal: 2m 43s\tremaining: 1m 9s\n",
      "4000:\tlearn: 0.9629986\ttest: 0.8771267\tbest: 0.8771267 (3040)\ttotal: 3m 5s\tremaining: 46.3s\n",
      "4500:\tlearn: 0.9654842\ttest: 0.8750000\tbest: 0.8771267 (3040)\ttotal: 3m 28s\tremaining: 23.1s\n",
      "4999:\tlearn: 0.9688249\ttest: 0.8745247\tbest: 0.8771267 (3040)\ttotal: 3m 50s\tremaining: 0us\n",
      "bestTest = 0.8771266541\n",
      "bestIteration = 3040\n",
      "Shrink model to first 3041 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x23802300610>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = Pool(\n",
    "    X_train_csr, \n",
    "    y_train\n",
    ")\n",
    "valid_pool = Pool(\n",
    "    X_test_csr, \n",
    "    y_test\n",
    ")\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': 5000,\n",
    "    'learning_rate': 0.01,\n",
    "    'eval_metric': 'F1',\n",
    "    'task_type': 'GPU',\n",
    "    'early_stopping_rounds': 2000,\n",
    "    'use_best_model': True,\n",
    "    'verbose': 500\n",
    "}\n",
    "model = CatBoostClassifier(**catboost_params)\n",
    "model.fit(train_pool, eval_set=valid_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csr = vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = model.predict(X_test_csr)\n",
    "\n",
    "best_score = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771266540642723\n"
     ]
    }
   ],
   "source": [
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"/home/dasha/Documents/ml_crash_course/data/model\")\n",
    "import pickle\n",
    "pickle.dump(vectorizer, open(\"/home/dasha/Documents/ml_crash_course/data/vectorizer.pickle\", \"wb\"))\n",
    "\n",
    "from_file = CatBoostClassifier()\n",
    "\n",
    "from_file.load_model(\"/home/dasha/Documents/ml_crash_course/data/model\")\n",
    "\n",
    "loaded_vectorizer = pickle.load(open(\"/home/dasha/Documents/ml_crash_course/data/vectorizer.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(messages : np.ndarray) -> pd.Series:\n",
    "    pd_messages = pd.Series(messages)\n",
    "    pd_messages = pd_messages.str.lower()\n",
    "    pd_messages = pd_messages.dropna()\n",
    "\n",
    "    preprocess_functions = [to_lower, remove_punctuation, remove_special_character, remove_number, remove_whitespace]\n",
    "\n",
    "    pd_messages = pd_messages.apply(lambda x: preprocess_text(x, preprocess_functions))\n",
    "\n",
    "    pd_messages = pd_messages.map(lambda x: bytes(x, 'utf-8').decode('utf-8', 'ignore'))\n",
    "\n",
    "    english_stopwords = stopwords.words(\"english\")\n",
    "    pd_messages = pd_messages.apply(lambda x: remove_stopword(x, english_stopwords))\n",
    "\n",
    "    russian_stopwords = stopwords.words(\"russian\")\n",
    "    pd_messages = pd_messages.apply(lambda x: remove_stopword(x, russian_stopwords))\n",
    "\n",
    "    greek_stopwords = stopwords.words(\"greek\")\n",
    "    pd_messages = pd_messages.apply(lambda x: remove_stopword(x, greek_stopwords))\n",
    "\n",
    "    turkish_stopwords = stopwords.words(\"turkish\")\n",
    "    pd_messages = pd_messages.apply(lambda x: remove_stopword(x, turkish_stopwords))\n",
    "\n",
    "    pd_messages = pd_messages.str.join(' ')\n",
    "\n",
    "    return pd_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "msg = '#аренда #квартира  #лимассол #агент.  ппрп: квартира / 1 спальня    абобус -в конце макариос авеню - апостолос андреас  трехэтажный жилой дом, расположенный в тихом, спокойном жилом районе лимассола, в непосредственной близости от центра города, с легким доступом к близлежащим школам, супермаркетам, а также многим другим услугам , новый порт , молл. квартира с 1 спальней  - открытого плана зал совмещен с кухней  душевая комната  и просторная веранда  крытая парковка и кладовая   все здание теплоизолированное с использованием энергосберегающих технологий класса а, а все окна оснащены двойным тепловым остеклением. квартира сдается  без мебели, будет  оборудована электроприборами и установлены кондиционеры. идеальное тихое место в центре города! цена снижена : €1,050 /per month (plus 1 deposit )'\n",
    "\n",
    "pre_proc = preprocessing(np.array( [msg] ))\n",
    "\n",
    "X_test_csr = loaded_vectorizer.transform(pre_proc)\n",
    "\n",
    "\n",
    "pred = from_file.predict(X_test_csr)\n",
    "\n",
    "print(pred[0])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
